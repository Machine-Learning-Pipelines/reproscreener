Your role is to evaluate the provided abstract from a scientific research paper to assess whether the explained metrics are present. The goal is to understand the given abstract and identify which metrics are observed. This would not just be a direct keyword search but will involve some understanding of the paragraph to interpret the presence of metrics. Respond using JSON containing the following 3 objects after evaluation:
- Evaluation metric
- Matched phrase. If the metric doesn't seem to be mentioned in the abstract, this will be empty.
- A score from between 0 and 1 indicating how likely that a match was found/corresponds to the metric description. Note that this would be 0 if the Matched phrase is not found.

Here is the list of 10 evaluation metrics with explanations and examples of what to look for:
```
1. Problem
- The problem the research seeks to solve
- This variable aims to capture whether the specific research problem that the paper is based on is mentioned in the paper. It does not include generalized statements.
- Also includes ‘research problem’, ‘problem’ or ‘problem statement’.

2. Objective
- The objective of the research
- Whether the goal or objective (or aim) of the paper is stated
- Example: “In this article we take a narrow interpretation of this goal, and attempt to regenerate published claims from author-supplied information, including data, code, inputs, and other provided specifications, on a different computational system than that used by the original authors.”

3. Research method
- The research method used
- Example: “A systematic review identified 14 prognostic models for late-stage ovarian cancer. For each, we evaluated its 1) reimplementation as described by the original study, 2) performance for prognosis of overall survival in independent data, and 3) performance compared with random gene signatures. We compared and ranked models by validation in 10 published datasets comprising 1251 primarily high-grade, late-stage serous ovarian cancer patients. All tests of statistical significance were two-sided.”

4. Research questions
- The research question(s) asked
- Specific questions to be answered in the paper (not as general as 2. Objective).
- Some papers use the format ‘RQ #1’
- Example: “This assessment addresses several important issues for the translation of genomics to clinical application: 1) the accuracy of published prognostic models when applied to new, independent datasets; 2) the impact of choice of validation datasets on apparent prognostic accuracy; 3)  similarities between independently developed prognostic models;”

5. Pseudocode
- Method described using pseudo code
- Whether the main methods used in the paper are described using pseudocode. If there are multiple methods that the paper is implementing, all of them have to be described using pseudocode. Some papers tend to caption this as ‘Algorithm #1’.

6. Dataset
- Is the datset made available or shared
- Is the training/test/validation set shared?

7. Hypothesis
- Hypotheses that the authors make prior to conducting the experiment

8. Prediction
- The predicted results by the authors

8. Method source code
- Is the code for the research open source and shared?
- Whether the code for all methods proposed in the paper are available in an open source repository (GitHub, GitLab, etc.). 

9. Software dependencies
- Software packages/dependencies used to run the code.

10. Experiment setup
- Is the experimental setup (hyperparameters, initial values, selected models, etc.) described?
- Details of the how the models are tested
```

For example:

1. Abstract of `1606.04671.txt`:

```
Learning to solve complex sequences of tasks--while both leveraging transfer
and avoiding catastrophic forgetting--remains a key obstacle to achieving
human-level intelligence. The progressive networks approach represents a step
forward in this direction: they are immune to forgetting and can leverage prior
knowledge via lateral connections to previously learned features. We evaluate
this architecture extensively on a wide variety of reinforcement learning tasks
(Atari and 3D maze games), and show that it outperforms common baselines based
on pretraining and finetuning. Using a novel sensitivity measure, we
demonstrate that transfer occurs at both low-level sensory and high-level
control layers of the learned policy.
```

Found metrics:
- Problem: "Learning to solve complex sequences of tasks--while both leveraging transfer
and avoiding catastrophic forgetting" is the research problem defined by the authors.
- Method: "Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy." would be the research method in this abstract.

Expected JSON output:
```
[
  {
    "evaluation_metric": "Problem",
    "matched_phrase": "Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting",
    "score": 1
  },
  {
    "evaluation_metric": "Objective",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Research method",
    "matched_phrase": "Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.",
    "score": 1
  },
  {
    "evaluation_metric": "Research questions",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Pseudocode",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Dataset",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Hypothesis",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Prediction",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Method source code",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Software dependencies",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Experiment setup",
    "matched_phrase": "",
    "score": 0
  }
]
```


2. Abstract of `2105.01937.txt`
```
The increasing availability of video recordings made by multiple cameras has
offered new means for mitigating occlusion and depth ambiguities in pose and
motion reconstruction methods. Yet, multi-view algorithms strongly depend on
camera parameters; particularly, the relative transformations between the
cameras. Such a dependency becomes a hurdle once shifting to dynamic capture in
uncontrolled settings. We introduce FLEX (Free muLti-view rEconstruXion), an
end-to-end extrinsic parameter-free multi-view model. FLEX is extrinsic
parameter-free (dubbed ep-free) in the sense that it does not require extrinsic
camera parameters. Our key idea is that the 3D angles between skeletal parts,
as well as bone lengths, are invariant to the camera position. Hence, learning
3D rotations and bone lengths rather than locations allows predicting common
values for all camera views. Our network takes multiple video streams, learns
fused deep features through a novel multi-view fusion layer, and reconstructs a
single consistent skeleton with temporally coherent joint rotations. We
demonstrate quantitative and qualitative results on three public datasets, and
on synthetic multi-person video streams captured by dynamic cameras. We compare
our model to state-of-the-art methods that are not ep-free and show that in the
absence of camera parameters, we outperform them by a large margin while
obtaining comparable results when camera parameters are available. Code,
trained models, and other materials are available on our project page.
```
Found metrics:
- Method source code: "Code, trained models, and other materials are available on our project page." implies that the source code has been provided
- "Data": "Code, trained models, and other materials are available on our project page." implies that the data has been provided

Expected JSON output:
```
[
  {
    "evaluation_metric": "Problem",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Objective",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Research method",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Research questions",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Pseudocode",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Dataset",
    "matched_phrase": "Code, trained models, and other materials are available on our project page.",
    "score": 1
  },
  {
    "evaluation_metric": "Hypothesis",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Prediction",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Method source code",
    "matched_phrase": "Code, trained models, and other materials are available on our project page.",
    "score": 1
  },
  {
    "evaluation_metric": "Software dependencies",
    "matched_phrase": "",
    "score": 0
  },
  {
    "evaluation_metric": "Experiment setup",
    "matched_phrase": "",
    "score": 0
  }
]
```

Here is the abstract to check:
```

```