<div align="center" id="top"> 
  <img src="./.github/reproscreener.png" alt="" />
</div>

<h1 align="center">reproscreener</h1>

<p align="center">
  <img alt="GitHub Workflow Status (with branch)" src="https://github.com/Machine-Learning-Pipelines/reproscreener/actions/workflows/ci.yml/badge.svg?branch=main">
    <img alt="GitHub deployments" src="https://img.shields.io/github/deployments/Machine-Learning-Pipelines/reproscreener/github-pages?label=build docs">
  <img alt="Codecov" src="https://codecov.io/gh/Machine-Learning-Pipelines/reproscreener/branch/main/graph/badge.svg?token=DWBDDAERY4">
  <img alt="PyPI" src="https://img.shields.io/pypi/v/reproscreener">
  <img alt="License" src="https://img.shields.io/github/license/Machine-Learning-Pipelines/reproscreener">

</p>

`reproscreener` is a tool designed to evaluate the reproducibility of papers and code to enhance trustworthy machine learning research. Please see the [project website](https://reproscreener.com/) for more information.

### License

Distributed under the MIT License. See `LICENSE.txt` for more information.

### Funding

We thank the The Center for Research and Education in AI and Learning (REAL@USC) for their funding and support towards this project.
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the The Center for Research and Education in AI and Learning (REAL@USC).

---

This material is based upon work supported by the National Science Foundation under Grant No. OAC 2138773

---