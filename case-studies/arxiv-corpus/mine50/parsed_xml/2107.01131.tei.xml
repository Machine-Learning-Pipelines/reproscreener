<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qing</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junya</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuewei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinwei</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Chenyang</forename><surname>Tao</surname></persName>
							<email>chenyang.tao@duke.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Duke University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C8D14E568A4F1BFE39CB591E30717C09</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-31T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Successful applications of InfoNCE (Information Noise-Contrastive Estimation) and its variants have popularized the use of contrastive variational mutual information (MI) estimators in machine learning. While featuring superior stability, these estimators crucially depend on costly large-batch training, and they sacrifice bound tightness for variance reduction. To overcome these limitations, we revisit the mathematics of popular variational MI bounds from the lens of unnormalized statistical modeling and convex optimization. Our investigation yields a new unified theoretical framework encompassing popular variational MI bounds, and leads to a new simple and powerful contrastive MI estimator we name FLO. Theoretically, we show that the FLO estimator is tight, and it converges under stochastic gradient descent. Empirically, the FLO estimator overcomes the limitations of its predecessors and learns more efficiently. The utility of FLO is verified using extensive benchmarks, and we further inspire the community with novel applications in meta-learning. Our presentation underscores the foundational importance of variational MI estimation in data-efficient learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Assessing the dependence between pairs of variables is integral to many scientific and engineering endeavors <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b69">70]</ref>. Mutual information (MI) is a popular metric to quantify generic associations <ref type="bibr" target="#b52">[53]</ref>, and its empirical estimators have been widely used in applications such as independent component analysis <ref type="bibr" target="#b7">[8]</ref>, fair learning <ref type="bibr" target="#b33">[34]</ref>, neuroscience <ref type="bibr" target="#b60">[61]</ref>, Bayesian optimization <ref type="bibr" target="#b46">[47]</ref>, among others. Notably, the recent advances in deep self-supervised learning (SSL) heavily rely on nonparametric MI optimization <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32]</ref>. In this study we investigate the likelihood-free variational approximation of MI using only paired samples, and improve the data-efficiency of current machine learning practices. MI estimation has been extensively studied <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b76">77]</ref>. While most classical estimators work reasonably well for low-dimensional cases, they scale poorly to big datasets: naïve density-based estimator(s) and k-nearest neighbor estimators <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b26">27]</ref> struggle with high-dimensional inputs, while kernel estimators are slow, memory demanding and sensitive to hyperparameters <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30]</ref>. Moreover, these estimators are usually either non-differentiable or need to hold all data in memory. Consequently, they are not well suited for emerging applications where the data representation needs to be differentiably optimized based on small-batch estimation of MI <ref type="bibr" target="#b41">[42]</ref>. Alternatively, one can approach MI estimation through an estimated likelihood ratio <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b41">42]</ref>, but the associated numerical instability has raised concerns <ref type="bibr" target="#b5">[6]</ref>.</p><p>To scale MI estimation to the growing size and complexity of modern datasets, and to accommodate the need for representation optimization <ref type="bibr" target="#b13">[14]</ref>, variational objectives have been widely utilized recently <ref type="bibr" target="#b59">[60]</ref>. Instead of directly estimating data likelihoods, density ratios, or the corresponding gradients <ref type="bibr" target="#b80">[81]</ref>, variational approaches appeal to mathematical inequalities to construct tractable lower or 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv:2107.01131v3 [stat.ML] 24 Oct 2022 upper bounds of the mutual information <ref type="bibr" target="#b64">[65]</ref>, facilitated by the use of auxiliary critic functions 1 . This practice turns MI estimation into an optimization problem. Prominent examples include the Barber-Agakov (BA) estimator <ref type="bibr" target="#b8">[9]</ref>, the Donsker-Varadhan (DV) estimator <ref type="bibr" target="#b20">[21]</ref>, and the Nguyen-Wainwright-Jordan (NWJ) estimator <ref type="bibr" target="#b57">[58]</ref>. These variational estimators are closely connected to the variational objectives for likelihood inference <ref type="bibr" target="#b0">[1]</ref>.</p><p>Despite reported successes, these variational estimators have a major limitation: their estimation variance grows exponentially to the ground-truth MI <ref type="bibr" target="#b54">[55]</ref>. This is especially harmful to applications involving deep neural nets, as it largely destabilizes training <ref type="bibr" target="#b71">[72]</ref>. An effective fix is to leverage multi-sample contrastive estimators, pioneered by the work of InfoNCE <ref type="bibr" target="#b59">[60]</ref>. However, the massive reduction in the variance comes at a price: the performance of the InfoNCE estimator is upper bounded by log K, where K is the number of negative samples used <ref type="bibr" target="#b64">[65]</ref>. For a large MI, K needs to be sufficiently large to allow for an adequate estimate, consequently placing a significant burden on computation and memory. While variants of InfoNCE have been motivated to achieve more controllable bias and variance tradeoffs <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b71">72]</ref>, little research has been conducted on the cost-benefit aspect of contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mutual Information</head><p>!(#; %)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BA</head><p>The Fenchel Family A critical insight enabled by InfoNCE is that mutual information closely connects to contrastive learning <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b59">60]</ref>. Paralleled by the empirical successes of instance discriminationbased self-supervision <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b37">38]</ref> and multi-view supervision <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b65">66]</ref>, InfoNCE offers an InfoMax explanation to why the ability to discriminate naturally paired positive instances from the randomly paired negative instances leads to universal performance gains in these applications <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b64">65]</ref>. Despite these encouraging developments, the big picture of MI optimization and contrastive learning is not yet complete: (i) There is an ongoing debate about to what extent MI optimization helps to learn <ref type="bibr" target="#b78">[79]</ref>; (ii) how does the contrastive view reconcile with those non-contrastive MI estimators; crucial for practical applications, (iii) are the empirical tradeoffs made by estimators such as InfoNCE absolutely necessary? And theoretically, (iv) formal guarantees on the statistical convergence of popular variational non-parametric MI estimation are missing currently.</p><p>In this work we seek to bridge the above gaps by approaching the MI estimation from the novel perspective of energy modeling. While this subject has recently been studied extensively using information-theoretic and variational inequalities, we embrace a new view from the lens of unnormalized statistical modeling. Our main contributions include:</p><p>• Unifying popular variational MI bounds under unnormalized statistical modeling;</p><p>• Deriving a simple but powerful novel contrastive variational bound called FLO;</p><p>• Providing theoretical justification of the FLO bound (tightness and convergence);</p><p>• Demonstrating strong empirical evidence of the superiority of FLO over its predecessors.</p><p>• Highlighting the importance of MI in data-efficient learning with novel applications</p><p>We contribute in-depth discussion to bridge the gaps between contrastive learning and MI estimation, along with principled practical guidelines informed by theoretical insights.</p><p>2 Fenchel-Legendre Optimization for Mutual Information Estimation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><p>This section briefly reviews the mathematical background needed for our subsequent developments.</p><p>Unnormalized statistical modeling defines a rich class of models of general interest. Specifically, we are interested in problems for which the system is characterized by an energy function pθ (x) = exp(−ψ θ (x)), where θ is the system parameters and ψ θ (x) is known as the potential function. The goal is to find a solution that is defined by a normalized version of pθ (x), i.e.,</p><formula xml:id="formula_0">min θ L pθ pθ (x ) dµ(x )</formula><p>, where L(•) is the loss function, µ is the base measure on X and Z(θ) pθ (x ) dµ(x ) is called the partition function for pθ (x). Problems in the above form arise naturally in statistical physics <ref type="bibr" target="#b67">[68]</ref>, Bayesian analysis <ref type="bibr" target="#b14">[15]</ref>, and maximal likelihood estimation <ref type="bibr" target="#b73">[74]</ref>. A major difficulty with unnormalized statistical modeling is that the partition function Z(θ) is generally intractable for complex energy functions 2 , and in many applications Z(θ) is further composed by log Z(θ), whose concavity implies any finite sample estimate Monte-Carlo of Z(θ) will render the loss function biased <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b87">88]</ref>. Bypassing the difficulties caused by the intractable partition function is central to unnormalized statistical modeling <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>Mutual information and unnormalized statistical models. As a generic score assessing the dependency between two random variables (X, Y ), mutual information is formally defined as the Kullback-Leibler divergence (KL) between the joint distribution p(x, y) and product of the respective marginals p(x)p(y) <ref type="bibr" target="#b69">[70]</ref>, i.e., I(X; Y ) E p(x,y) log p(x,y) p(x)p(y) . The integrand log p(x,y) p(x)p(y) is often known as the point-wise mutual information (PMI) in the literature. Mutual information has a few appealing properties: (i) it is invariant wrt invertible transformations of x and y, and (ii) it has the intuitive interpretation of reduced uncertainty of one variable given another variable 3 .</p><p>To connect MI to unnormalized statistical modeling, we consider the classical Barber-Agakov (BA) estimator of MI <ref type="bibr" target="#b9">[10]</ref>. To lower bound MI, BA introduces a variational approximation q(y|x) for the posterior p(y|x), and by rearranging the terms we obtain an inequality</p><formula xml:id="formula_1">I(X; Y ) = E p(x,y) log p(y|x) p(y) = E p(x,y) log q(y|x) p(y) + E p(x) [KL(p(y|x) q(y|x))] ≥ E p(x,y) log q(y|x) p(y) I BA (X; Y |q).<label>(1)</label></formula><p>Here we have used notation I BA (X; Y |q) to highlight the dependence on q(y|x), and when q(y|x) = p(y|x) this bound is sharp. Unfortunately, this naïve BA bound is not useful for sample-based MI estimation, as we do not know the ground-truth p(y). But we can bypass this difficulty by setting q θ (y|x) = p(y) Z θ (x) e g θ (x,y) , where we call e g θ (x,y) the tilting function and recognize Z θ (x) = E p(y) [e g θ (x,y) ] as the associated partition function. Substituting this q θ (x|y) into (S18) gives the following unnormalized BA bound (UBA) that pertains to unnormalized statistical modeling <ref type="bibr" target="#b64">[65]</ref> </p><formula xml:id="formula_2">I UBA (X; Y |g θ ) E p(x,y) [g θ (x, y) − log Z θ (x)] = E p(x) E p(y|x) log e g θ (x,y) Z θ (x) .<label>(2)</label></formula><p>While this UBA bound remains intractable, now with Z θ (x) instead of p(y) we can apply different techniques for empirical estimates of Z θ (x) to render a tractable surrogate target. This has led to various popular MI bounds listed in Table <ref type="table">1</ref> (see Appendix A for derivations).</p><p>InfoNCE and noise contrastive estimation. InfoNCE is a multi-sample mutual information estimator proposed in <ref type="bibr" target="#b59">[60]</ref>, built on the idea of noise contrastive estimation (NCE) <ref type="bibr" target="#b34">[35]</ref>. NCE learns statistical properties of a target distribution by comparing the positive samples from the target distribution to the "negative" samples from a carefully crafted noise distribution, and this technique is also known as negative sampling in some contexts <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b32">33]</ref>. The InfoNCE estimator implements this contrastive estimation idea via using the naïve empirical estimate of Z θ (x) in UBA 4 , i.e.</p><formula xml:id="formula_3">I K InfoNCE (X; Y |g θ ) E p K (x,y) log e g θ (x1,y1) 1 K j e g θ (x1,yj ) , I K InfoNCE (X; Y ) max g θ ∈F {I K InfoNCE (X; Y |g θ )},<label>(3)</label></formula><p>where g θ is known as the critic in the nomenclature of contrastive learning, and we have used p K (x, y) to denote K independent draws from the joint density p(x, y), and {(x k , y k )} K k=1 for each pair of samples. Here the positive and negative samples are respectively drawn from the joint p(x, y) and product of marginals p(x)p(y). Intuitively, InfoNCE tries to accurately classify the positive samples when they are mixed with negative samples, and the Proposition below formally characterizes InfoNCE's statistical properties as a MI estimator.</p><p>Fenchel-Legendre duality. Our key idea is to exploit the convex duality for MI estimation. Let f (t) be a proper convex, lower-semicontinuous function; then its convex conjugate function is defined as f * (v) sup t∈D(f ) {tv − f (t)}, where D(f ) is the domain of function f <ref type="bibr" target="#b40">[41]</ref>. We call f * (v) the Fenchel conjugate of f (t), which is also known as the Legendre transform in physics. The Fenchel conjugate pair (f, f * ) are dual to each other, in the sense that f * * = f , i.e.,</p><formula xml:id="formula_4">f (t) = sup v∈D(f * ) {vt − f * (v)}. For f (t) = − log(t) and its Fenchel conjugate f * (v) = −1 − log(−v), we have inequality − log(t) ≥ −u − e −u t + 1, for u ∈ R<label>(4)</label></formula><p>with the equality holds when u = log(t). ). InfoNCE is an asymptotically tight mutual information lower bound, i.e.</p><formula xml:id="formula_5">I K InfoNCE (X; Y |g θ ) ≤ I(X; Y ), lim K→∞ I K InfoNCE (X; Y ) → I(X; Y ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fenchel-Legendre Optimization for tight mutual information estimation</head><p>With the above mathematical tools, we are ready to present the main result of this paper: a tight, data-efficient variational MI lower bound that can be efficiently implemented.</p><p>Lower bounding MI with Fenchel-Legendre Optimization. Our key insight is that MI estimation is essentially an unnormalized statistical model, which can be efficiently handled by the Fenchel-Legendre transform technique. Take the integrand from UBA in (S21) and we can rewrite it as</p><formula xml:id="formula_6">log exp(g θ (x, y)) Z θ (x) = − log E p(y ) [exp(g(x, y ) − g(x, y))] ,<label>(5)</label></formula><p>where p(y ) is the same probability density as p(y) (i.e., Y is an independent copy of Y ). Now let us use the Fenchel inequality of − log(t) from ( <ref type="formula" target="#formula_4">4</ref>), plugging it into the above equation and then we have</p><formula xml:id="formula_7">log exp(g θ (x, y)) Z θ (x) ≥ −u − e −u E p(y ) [exp(g(x, y ) − g(x, y))] + 1.<label>(6)</label></formula><p>for all u ∈ R. This implies for any function u φ (x, y) : X × Y → R, the following inequality holds log exp(g θ (x, y)) Z θ (x) ≥ −{u φ (x, y) + e −u φ (x,y) E p(y ) [exp(g(x, y ) − g(x, y))]} + 1.</p><p>By putting <ref type="bibr" target="#b6">(7)</ref> back to (S21), we obtain our new Fenchel-Legendre Optimization (FLO) MI lower bound</p><formula xml:id="formula_9">I FLO (X; Y |g θ , u φ ) E p(x,y) −{u φ (x, y) + e −u φ (x,y) E p(y ) [e g θ (x,y )−g θ (x,y) ]} + 1,<label>(8)</label></formula><p>and concludes the proof for the following Proposition. Proposition 2.2.</p><formula xml:id="formula_10">I FLO (X; Y |g θ , u φ ) ≤ I UBA (X; Y |g θ ) ≤ I(X; Y ).</formula><p>In practice, FLO can be estimated with the following naïve empirical K-sample estimator</p><formula xml:id="formula_11">ÎK FLO (X; Y |g θ , u φ ) −    u φ (x i , y i ) + e −u φ (xi,yi) 1 K − 1 j =i e g θ (xi,yj )−g θ (xi,yi)    + 1.<label>(9)</label></formula><p>Since the summation in ÎK FLO is not encapsulated by a convex log transformation,</p><formula xml:id="formula_12">I K FLO E p K [ ÎK FLO</formula><p>] is an unbiased estimator for I FLO (X; Y |g θ , u φ ) independent of the batch size K (see Figure <ref type="figure">2</ref>).</p><p>Why is the FLO bound more appealing? At first sight, it may appear counter-intuitive that I FLO is a better MI bound compared to prior arts such as NWJ or InfoNCE: it seems to be more complicated as an extra variational function u φ (x, y) has been introduced. To answer this question, we next explain the statistical meaning of the newly introduced u φ (x, y), and establish some important statistical properties of FLO that makes it more favorable: that I FLO is tight, meaning the ground-truth MI can be recovered for some specific choice of g θ (x, y) and u φ (x, y); and that I K FLO for any batch size K is effectively optimizing InfoNCE with an infinite batch size. And in Sec 2.4, we further justify FLO's advantages from optimization perspectives.</p><p>Given the close connection between FLO and UBA, we first recall UBA's optimal critic that gives the tight MI estimate is g * (x, y) = log p(x|y) + c(x), where this c(x) can be any function of x <ref type="bibr" target="#b51">[52]</ref>. This g * (x, y) is not directly meaningful in a statistical sense, however, by integrating out y , we have</p><formula xml:id="formula_13">E p(y ) e g * (x,y )−g * (x,y) = E p(y ) p(x|y ) p(x|y) = p(x) p(x|y) = p(x)p(y) p(x, y) ,<label>(10)</label></formula><p>which is the likelihood ratio between the marginals and joint. On the other hand, based on the Fenchel-Legendre inequality (4), we know for fixed g(x, y) our FLO bound in (8) can be maximized with u g (x, y) = log E p(y ) e g(x,y )−g(x,y) . Putting these all together we have u g * (x, y) = − log p(x,y) p(x)p(y) . This shows the u φ (x, y) introduced in FLO actually tries to recover the negative PMI. Comparing to the competing MI bounds that only optimizes for g θ , eliminating the drift term c(x) reveals FLO enjoys the appealing self-normalizing property <ref type="bibr" target="#b34">[35]</ref> that helps stabilize training. Plugging (g * , u g * ) into (8), we readily see I FLO (X; Y |u g * , g * ) = I(X; Y ), proving FLO is a tight MI bound. Proposition 2.3. The FLO estimator is tight, the eqaulity holds when g(x, y) = log p(x|y) + c(x) for arbitrary function c(x) and u(x, y) = − log p(x,y) p(x)p(y) . Corollary 2.4. Let (g * , u g * ) be the maximizers for <ref type="bibr" target="#b7">(8)</ref>, then</p><formula xml:id="formula_14">I(X; Y ) = E p(x,y) [−u g * (x, y)].</formula><p>Finally, we give a simple asymptotic argument showing FLO essentially optimizes InfoNCE with an infinite batch size. In virtue of the law of large numbers, we have the denominator in InfoNCE converging to lim K→∞ 1 K K j=1 e g θ (xi,yj ) → E p(y ) [e g θ (xi,y ) ] = Z θ (x i ), and consequently it recovers the UBA bound. Since FLO is derived from UBA, we can view FLO as using the optimization of u φ (x, y) to amortize the difficulty of evaluating infinite number of e g θ (xi,yj ) with InfoNCE.</p><p>Efficient implementations of FLO. A lingering concern is that the newly introduced u φ (x, y) can incur extra computation overhead. This is not true, as we can maximally encourage parameter sharing by jointly model u φ (x, y) and g θ (x, y) with a single neural network f Ψ (x, y) : X ×Y → R 2 with two output heads, i.e., [u i , g i ] = f Ψ (x i , y i ). Consequently, while FLO adopts a dual critics design, it does not actually invoke extra modeling cost compared to its single-critic counterparts (e.g., InfoNCE). Experiments show this shared parameterization in fact promotes synergies and speeds up learning (see our ablation studies in Appendix).</p><p>To further enhance the computation efficiency, we consider a massively parallelized bi-linear critic design that uses all in-batch samples as negatives. Let g θ (x, y) = τ • h θ (x), h(y) , where h : X → S p and h : Y → S p are respectively encoders that map data to unit sphere S p embedded in R p+1 , a, b = a T b is the inner product operation, and τ &gt; 0 is the inverse temperature parameter. Thus the evaluation of the Gram matrix G = τ • h(X) T h(Y), where [X, Y] ∈ R K×(dx+dy) is a mini-batch of K-paired samples and g θ (x i , y j ) = G ij , can be parallelized via matrix multiplication. In this setup, the diagonal terms of G are the positive scores while the off-diagonal terms negative scores. A similar strategy has been widely employed in the contrastive representation learning literature (e.g., <ref type="bibr" target="#b18">[19]</ref>) 5 . We can simply model the PMI critic as u(x, y) = MLP(h(x), h(y)), whose computation cost is almost neglectable in practice, where feature encoders h, h dominate computing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Connections to the existing MI bounds</head><p>Due to space limitations, we elaborate the connections to the existing MI bounds here, and have relegated an extended related work discussion in a broader context to the Appendix.</p><p>From log-partition approximation to MI bounds. To embrace a more holistic understanding, we list popular variational MI bounds together with our FLO in Table <ref type="table">1</ref>, and visualize their connections in Figure <ref type="figure" target="#fig_0">1</ref>. With the exception of JSD, these bounds can be viewed from the perspective of unnormalized statistical modeling, as they differ in how the log partition function log Z(x) is estimated. We broadly Table <ref type="table">1</ref>: Comparison of popular variational MI estimators. Here g(x, y), u(x, y) and u(x) are variational functions to be optimized, σ(u) = 1 1+exp(−u) is the Sigmoid function, E[f (u), η] denotes exponential average of function f (u) with decay parameter η ∈ (0, 1), and α ∈ [0, 1] is the balancing parameter used by α-InfoNCE trading off bias and variance between InfoNCE and TUBA. we use (x i , y i ) to denote positive samples from the joint density p(x, y), and (x i , y j ) or (x k , y k ) to denote negative samples drawn from the product of marginal p(x)p(y). In context, y ⊕ and y have the intuitive interpretation of positive and negative samples. We exclude variational upper bounds here because their computations typically involve the explicit knowledge of conditional likelihoods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head><p>Objective Bias Var. Converge</p><formula xml:id="formula_15">(x i , y i ) iid ∼ p(x, y), (x k , y k ) iid ∼ p(x)p(y), m α,u (x, y 1:K ) α 1 K K k=1 exp(g(x, y k )) + (1 − α) exp(u(x)) DV [21] g(x i , y i ) − log( K k=1 exp(g(x k , y k ))/K) high high no MINE [12] g(x i , y i ) − log(E[exp(g(x i , y j )), η]) low high no NWJ [58] g(x i , y i ) − exp(g(x i , y j ) − 1) low high no JSD [42] g * (x i , y i ) − exp(g * (x i , y j ) − 1) low high no g * arg max ← −−−− − {log σ(g(x i , y i )) + log σ(−g(x i , y j ))} TUBA [65] g(x i , y i ) + u(x i ) + 1 − exp(g(x i , y j ) − u(x i )) low high no InfoNCE [60] g(x i , y i ) − log( j exp(g(x i , y j ))/K) high low no α-InfoNCE [65] g(x i , y i ) − g(x i , y j ) − log(m α,u (x, y 1:K )) + log(m α,u (x k , y k )) no α-InfoNCE interpolates between low-bias high-var (α → 1, NWJ) to high-bias low-var (α → 0, InfoNCE) FLO (ours) −u(x i , y i ) − exp(−u(x i , y i ) + g(x i , y j ) − g(x i , y i )) low moderate yes</formula><p>categorize these estimators into two families: the log-family (DV, MINE, InfoNCE) and the exponentialfamily (NWJ, TUBA, FLO). In the log-family, DV and InfoNCE are multi-sample estimators that leverage direct Monte-Carlo estimates Ẑ for log Z(x), and these two differ in whether to include the positive sample in the denominator or not. To avoid the excessive in-batch computation of the normalizer and the associated memory drain, MINE further employed an exponential moving average (EMA) to aggregate the normalizer across batches. Note for the log-family estimators, their variational gaps are partly caused by the log-transformation on finite-sample average due to Jensen's inequality (i.e., log</p><formula xml:id="formula_16">Z = log E[ Ẑ] ≥ E[log Ẑ]).</formula><p>In contrast, the objective of exponential-family estimators do not involve such log-transformation, since they can all be derived from the Fenchel-Legendre inequality: NWJ directly applies the Fenchel dual of f -divergence for MI <ref type="bibr" target="#b58">[59]</ref>, while TUBA exploits this inequality to compute the log partition log Z(x) = log E p(y ) [exp(g(x, y ))]. Motivated from a contrastive view, our FLO applies the Fenchel-Legendre inequality to the log-partition of contrast scores.</p><p>A contrastive view for MI estimation. The MI estimators can also be categorized based on how they contrast the samples. For instance, NWJ and TUBA are generally considered to be non-contrastive estimators, as their objectives do not compare positive samples against negative samples on the same scale (i.e., log versus exp), and this might explain their lack of effectiveness in representation learning applications. For JSD, it depends on a two-stage estimation procedure similar to that in adversarial training to assess the MI, by explicitly contrasting positive and negative samples to estimate the likelihood ratio. This strategy has been reported to be unstable in many empirical settings.</p><p>The log-family estimators can be considered as a multi-sample, single-stage generalization of JSD.</p><p>However, the DV objective can go unbounded thus resulting in a large variance, and the contrastive signal is decoupled by the EMA operation in MINE. Designed from contrastive perspectives, InfoNCE trades bound tightness for a lower estimation variance, which is found to be crucial in representation learning applications. Our FLO formalizes the contrastive view for exponential-family MI estimation, and bridges existing bounds: the PMI normalizer exp(−u(x, y)) is a more principled treatment than the EMA in MINE, and compared to DV the positive and negative samples are explicitly contrasted and adaptively normalized.</p><p>Important FLO variants. We now demonstrate that FLO is a flexible framework that not only recovers existing bounds, but also derives novel bounds such as</p><formula xml:id="formula_17">I FDV StopGrad[I DV ({(x i , y i )})] + j exp(c θ (xi,yi,yj )) StopGrad[ j exp(c θ (xi,yi,yj ))] − 1.<label>(11)</label></formula><p>Recall the optimal g * (x, y) = log p(x|y) + c(x) and u * (x, y) = − log p(x,y) p(x)p(y) , which motivates us to parameterize u(x, y) in the form of −g θ (x, y) + s ψ (x), where s ψ (x) models the arbitrary drift c(x), and this recovers the TUBA bound. Additionally, we note that (i) fixing either of u and g, and optimizing the other also gives a valid lower bound to MI; and (ii) a carefully chosen multi-input u({(x i , y i )}) can be computationally appealing. As a concrete example, if we set u φ to u θ ({(x i , y i )}) ← log 1 K j e c(xi,yi,yj ;g θ ) and update u θ (x, y) while artificially keeping the critic g θ (x, y) fixed 6 , then FLO falls back to DV. Alternatively, we can consider the Fenchel dual version of it: using the same multi-input u θ ({(x i , y i )}) above, treat u φ as fixed and only update g θ , and this gives us the novel MI objective in <ref type="bibr" target="#b10">(11)</ref>, we call it Fenchel-Donsker-Varadhan (FDV) estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Gradient and convergence analysis of FLO</head><p>In this section, we will establish that FLO better optimizes the MI because its gradient is more accurate than competing variational bounds such as NWJ and TUBA; also, we provide the first convergence analysis for variational MI estimation by showing FLO converges under SGD.</p><p>First, recall most tractable variational MI bounds are derived from and upper bounded by the intractable UBA bound <ref type="bibr" target="#b64">[65]</ref>. For instance, with the same critic g θ we have I NWJ ≤ I TUBA ≤ I UBA . So if we can show ∇ θ I FLO ≈ ∇ θ I UBA then FLO is better optimized. To simplify notations, we denote c θ (x, y, y ) g θ (x, y ) − g θ (x, y) and E θ (x, y) 1/E p(y ) [e c θ (x,y,y ) ], and we can easily verify</p><formula xml:id="formula_18">E p(y ) ∇ θ e c θ (x,y,y ) = ∇ θ 1 E θ (x, y) = − ∇E θ (x, y) (E θ (x, y)) 2 = − ∇ θ log E θ (x, y) E θ (x, y) . (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>Since for fixed g θ (x, y) the corresponding optimal u * θ (x, y) maximizing <ref type="formula" target="#formula_4">4</ref>)), we see that the term e −u φ (x,y) is essentially optimized to approximate E θ (x, y). To emphasize this point, we now write Êθ (x, y) e −u φ (x,y) . When this approximation is sufficiently accurate (i.e., E θ ≈ Êθ ), we can see that ∇I FLO approximates ∇I UBA as follows</p><formula xml:id="formula_20">I FLO (u φ , g θ ) 1 − u φ (x, y) + E p(y ) [e −u φ (x,y)+c(x,y,y ;g θ ) ] is given by u * θ (x, y) = log E p(y ) [e c θ (x,y,y ) ] = − log E θ (x, y) (using (</formula><formula xml:id="formula_21">∇ θ {I FLO (u φ , g θ )} = −E xy e −u φ (x,y) E y [∇ θ e c θ (x,y,y ) ] = E xy Êθ (x,y) E θ (x,y) ∇ θ log E θ (x, y) ≈ E xy [∇ θ log E θ (x, y)] = ∇ θ E p(x,y) [log E θ (x, y)] = ∇ θ {I UBA (g θ )}. (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>We can prove FLO will converge under much weaker conditions, even when this approximation û(x, y) is rough. The intuition is as follows: in <ref type="bibr" target="#b12">(13)</ref>, the term Êθ t E θ t only rescales the gradient, so the optimizer is still proceeding in the same direction as UBA in SGD. The informal version of our result is summarized in the Proposition below (see the Appendix for the formal version and proof).</p><formula xml:id="formula_23">Proposition 2.5 (Convergence of FLO, informal version). Let {η t } ∞ t=1 be the stochastic Robbins-Monro sequence of learning rates: t E[η t ] = ∞ and t E[η 2 t ] &lt; ∞. If Êθ t E θ t is bounded between [a, b] (0 &lt; a &lt; b &lt; ∞)</formula><p>, then under the stochastic gradient descent scheme described in Algorithm 1, θ t converges to a stationary point of I UBA (g θ ) with probability 1, i.e., lim t→∞ ∇I UBA (g θt ) = 0. Additionally assume I UBA is convex with respect to θ, then FLO converges with probability 1 to the global optimum θ * of I UBA from any initial point θ 0 .</p><formula xml:id="formula_24">Algorithm 1 FLO Empirical data pd = {(x i , y i )} n i=1 Model parameters Ψ = (θ, φ) for t = 1, 2, • • • do Sample i, j iid ∼ [n] u ii = u φ (x i , y i ), g ii = g θ (x i , y i ), g ij = g θ (x i , y j ) F = u ii + exp(−u ii + g ij − g ii ) Ψ t = Ψ t − η t ∇ Ψ F end for</formula><p>Importantly, this marks the first convergence result for variational MI estimators. The convergence analyses for MI estimation is non-trivial and scarce even for those standard statistical estimators <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b66">67]</ref>. The lack of convergence guarantees has led to a proliferation of unstable MI-estimators used in practice (in particular, DV, JSD, and MINE) that critically rely on various empirical hacks to work well (see discussions in <ref type="bibr" target="#b71">[72]</ref>). Our work establishes a family of variational MI estimators that provably converges, a contribution we consider significant as it fills an important gap in current literature on both theoretical and practical notes.  Figure <ref type="figure">4</ref>: Bayesian Optimal Experiment Design results. FLO consistently performs best, demonstrating superior strength in learning efficiency and robustness. NWJ takes the runner-up, but it has larger variance and is sensitive to network initializations. InfoNCE is less competitive due to low sample inefficiency, but its smaller variance helps in the more challenging dynamic case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We consider an extensive range of tasks to validate FLO and benchmark it against state-of-theart solutions. To underscore the practical significance of MI in efficient machine learning, we demonstrate example applications from data collection (in statistical parlance, experimental design), self-supervised pre-training, to meta/transfer-learning. Limited by space, we present only the key results in the main text, and defer ablation studies and details of our experimental setups to the Appendix. Our code is available from https://github.com/qingguo666/FLO. All experiments are implemented with PyTorch.</p><p>Comparison to baseline MI bounds. We start by comparing FLO to the following popular competing variational estimators: NWJ, TUBA, and InfoNCE. We use the bilinear critic implementation for all models which maximally encourages both sample efficiency and code simplicity, and this strategy does perform best based on our observations. We consider the synthetic benchmark from <ref type="bibr" target="#b64">[65]</ref>, where</p><formula xml:id="formula_25">(X ∈ R d , Y ∈ R d</formula><p>) is jointly standard Gaussian with diagonal cross-correlation parameterized by ρ ∈ [0, 1). We report d = 10 and ρ ∈ [0, 0.99] here (other studies only report ρ up to 0.9, which is less challenging.), providing a reasonable coverage of the range of MI one may encounter in empirical settings. Figure <ref type="figure" target="#fig_8">5</ref>: FLO compares favorably to classical MI estimators. To focus on the bias-variance trade-off, we plot the decimal quantiles in addition to the estimated MI in Figure <ref type="figure" target="#fig_2">3</ref>, where FLO significantly outperformed its variational counterparts in the more challenging high-MI regime. In Figure <ref type="figure" target="#fig_8">5</ref>, we show FLO also beats classical MI estimators <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b27">28]</ref>. In the Appendix I, we further discuss recent works on parametric estimators <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b15">16]</ref> and alternative information metrics <ref type="bibr" target="#b84">[85]</ref>.</p><p>Bayesian optimal experiment design (BOED). We next direct our attention to BOED, a topic of significant interest shared by the statistical and machine learning communities <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b25">26]</ref>. The performance of machine learning models crucially relies on the quality of data supplied for training, and BOED is a principled framework that optimizes the data collection procedure (in statistical parlance, conducting experiments) <ref type="bibr" target="#b24">[25]</ref>. Mathematically, let x be the data to be collected, θ be the parameters to be inferred, and d be the experiment parameters the investigator can manipulate (a.k.a, the design parameters), BOED tries to find the optimal data collection procedure that is expected to generate data that is most informative about the underlying model parameters, i.e., solves for arg max d I(x; θ; d). In this study, we focus on the more generic scenario where explicit likelihoods are not available, but we can still sample from the data generating procedure <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>We consider three carefully-selected models from recent literature for their progressive practical significance and the challenges involved <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46]</ref>: static designs of (i) a simple linear regression model and (ii) a complex nonlinear pharmacokinetic model for drug development; and the dynamic policy design for (iii) epidemic disease surveillance and intervention (e.g., for Covid-19 modeling). Designs with higher MI are more favorable, because it implies the data carries more information. In Figure <ref type="figure">4</ref> we compare design optimization curves using different MI optimization strategies, where FLO consistently leads. Popular NWJ and InfoNCE reports different tradeoffs that are less susceptible to FLO. We also examine the FLO predicted posteriors and confirm they are consistent with the ground-truth parameters (Figure <ref type="figure" target="#fig_4">6</ref> right). For the dynamic policy optimization, we also manually inspect the design strategies reported by different models (Figure <ref type="figure" target="#fig_4">6</ref> left,middle). Consistent with human judgement, FLO policy better assigns budgeted surveillance resources at different stages of pandemic progression.</p><p>A novel meta-learning framework. A second application of our work is to meta-learning, an area attracting substantial recent interest. In meta-learning, we are concerned with scenarios that at training time, there are abundant different labelled tasks, while upon deployment, only a handful of labeled instances are available to adapt the learner to a new task. Briefly, for an arbitrary loss t (ŷ, y), where t is the task identifier and ŷ = f (x) is the prediction made by the model, we denote the risk by</p><formula xml:id="formula_26">R t (f ) = E pt(x,y) [ t (f (x), y)]. Denote R(f ) E t∼p(t) [R t (f )]</formula><p>as the expected risk for all tasks and R(f ) for the mean of empirical risks computed from all training tasks. Inspired by recent information-theoretic generalization theories <ref type="bibr" target="#b83">[84]</ref>, we derived a novel, principled objective</p><formula xml:id="formula_27">L Meta-FLO (f ) = R(f ) + λ I FLO ( Dt ; Êt ),<label>(14)</label></formula><p>where λ is known given the data size and loss function, ( Dt , Êt ) are respectively data and task embeddings for training data, which for the first time lifts contrastive learning to the task and data distribution level. Our reasoning is that L Meta-FLO (f ) theoretically bounds R(f ) from above, and it is relatively sharp for being data-dependent. We give more information on this in the Appendix and defer a full exposition to a dedicated paper due to independent interest and space limits here. Note other MI bounds are not suitable for this task due to resource and vari-  a Note SpecNCE does not explicitly target mutual information ance concerns. In Figure <ref type="figure" target="#fig_5">7</ref> we show Meta-FLO wins big over the state-of-the-art model agnostic meta-learning (MAML) model on the regression benchmark from <ref type="bibr" target="#b22">[23]</ref>.   Self-supervised learning (SSL). Finally, we wrap our experiments with one of the prime applications of contrastive MI estimation in machine learning: SSL for model pre-training. Here we focus on how FLO-inspired objectives can improve the current practice of SSL, and given this topic's independent interest, we defer in-depth discussions in our dedicated work <ref type="bibr" target="#b17">[18]</ref> where SSL-specific problems such as training diagnosis and low-precision numerical overflow are explored in detail. In this experiment, we follow the SSL setup described in the SimCLR paper <ref type="bibr" target="#b18">[19]</ref>: in the pre-training phase, we optimize the mutual information between difference augmentations of the same image (i.e., scaling, rotation, color jitting, etc.); and use linear probing accuracy as our perfromance criteria. We compare the effectiveness of the InfoNCE-based SimCLR framework <ref type="bibr" target="#b18">[19]</ref> to our FLO-based alternatives. To ensure fair comparison, we have used the FDV variant defined in Eq. ( <ref type="formula" target="#formula_17">11</ref>) as our training objective, so that we are not introducing extra parameters to model u(x, y). We call our new model FlatCLR because, perhaps counter-intuitively, the second term in Eq. ( <ref type="formula" target="#formula_17">11</ref>) contributing all the learning signal is constant one in value (i.e., being flat). In Figure <ref type="figure" target="#fig_6">8</ref> and 9, we show our new model FlatCLR shows superior sample efficiency compared to the SOTA SimCLR (a 8× boost for the same performance, FlatCLR-32 versus SimCLR-256). This result is significant because SimCLR's crucial reliance on large-batch training is a well-known limitation <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b49">50]</ref>. Figure <ref type="figure" target="#fig_7">10</ref> shows typical training curves with the respective models. Note that while the empirical estimates of MI are tied between the two methods, FDV optimized representation enjoys a better ground-truth MI 7 , which can be explained by its robustness to the numerical overflow issue (see <ref type="bibr" target="#b17">[18]</ref> for details). Further comparisons on the ground-truth MI estimation with different estimators can be found in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have described a new framework for the contrastive estimation of mutual information from energy modeling perspectives. Our work not only encapsulates popular variational MI bounds but also inspires novel objectives such as FLO and FDV, which comes with strong theoretical guarantees. In future work, we will leverage our theoretical insights to improve practical applications involving MI estimation, such as representation learning, fairness, and in particular, data efficient learning.</p><p>(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A] (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? So for arbitrary multi-sample critic f (x; y 1:K ), we know</p><formula xml:id="formula_28">I(X; Y ) = I(X 1 ; Y 1:K ) ≥ I NWJ (X 1 , Y 1:K ; f ) = E p(x1,y1) k&gt;1 p(y k ) [f (x 1 , y 1:K )]−e −1 E p(x) [Z f (x)] (S26) Now let us set f (x 1 ; y 1:K ) = 1 + log e g(x1,y1) m(x 1 ; y 1:K ) , m(x 1 ; y 1:K ) = 1 K k e g(x1,y k ) . (S27) I NWJ (X 1 , Y 1:K ; f ) =E p(x1,y1)p K−1 (y k ) 1 + log e g(x1,y1) m(x 1 ; y 1:K ) − E p(x )p K (y ) e</formula><p>−1+1+log e g(x 1 ,y 1 )</p><formula xml:id="formula_29">m(x 1 ;y 1:K ) = E p(x1,y1)p K−1 (y k ) 1 + log e g(x1,y1) m(x 1 ; y 1:K ) − E p(x )p K (y ) e g(x 1 ,y 1 ) m(x 1 ; y 1:K )</formula><p>Due to the symmetry of {y k } K k=1 , we have</p><formula xml:id="formula_30">E p(x )p K (y ) e g(x 1 ,y 1 ) m(x 1 ; y 1:K ) = E p(x )p K (y ) e g(x 1 ,y k ) m(x 1 ; y 1:K ) . (<label>S28</label></formula><formula xml:id="formula_31">)</formula><p>So this gives</p><formula xml:id="formula_32">E p(x )p K (y ) e g(x 1 ,y 1 ) m(x 1 ; y 1:K ) = E p(x )p K (y ) 1 K e g(x 1 ,y k ) m(x 1 ; y 1:K ) = 1,<label>(S29)</label></formula><p>and one can easily see this recovers the K-sample InfoNCE defined in (3)</p><formula xml:id="formula_33">I NWJ (X 1 , Y 1:K ; f ) = E p(x1,y1)p K−1 (y k ) log e g(x1,y1) m(x 1 ; y 1:K ) = I K InfoNCE (X; Y |g) (S30)</formula><p>Now we need to show this bound is sharp when K → ∞. We only need to show that for some choice of g(x, y), the inequality holds asymptotically. Recall the NWJ's optimal critic takes value of f * (x, y) = 1 + p(x|y) p(x) , so with reference to (S27) let us plug in g * (x, y) = p(y|x) p(y) into InfoNCE</p><formula xml:id="formula_34">L * K = E p K log f * (x k , y k ) f * (x k , y k ) + k =k f * (x k , y k ) + log K (S31) = −E log 1 + p(y) p(y|x) k p(y k |x k ) p(y k ) + log K (S32) ≈ −E log 1 + p(y) p(y|x) (K − 1)E y k p(y k |x k ) p(y k ) + log K (S33) = −E log 1 + p(y k ) p(y k |x k ) (K − 1) + log K (S34) ≈ −E log p(y) p(y|x) − log(K − 1) + log K (S35) (K → ∞) → I(X; Y ) (S36)</formula><p>This concludes our proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Proposition 2.2 (FLO lower bounds MI)</head><p>Proof. The proof is given in line 133-140 in the main text. Basically we have applied the Fenchel duality trick to the log term in the UBA bound. Note that unlike UBA, our FLO bound can be unbiased estimated with finite samples (as UBA requires an infinite sum inside its log term, which makes finite-sample empirical estimate biased per Jensen's inequality).</p><p>C Proof of Proposition 2.3, Corollary 2.4 (FLO tightness, meaning of u(x, y))</p><p>Proof. The proof is given in the main text, more specifically the paragraph preceding Proposition 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Gradient Analysis of FLO (More Detailed)</head><p>To further understand the workings of FLO, let us inspect the gradient of model parameters. Recall the intractable UBA MI estimator can be re-expressed in the following form:</p><formula xml:id="formula_35">I UBA (g θ ) = E p(x,y) [− log E p(y ) [exp(g θ (x, y ) − g θ (x, y))]] (S37)</formula><p>In this part, we want to establish the intuition that ∇ θ {I FLO (u φ , g θ )} ≈ ∇ θ {I UBA (g θ )}, where Êθ (x, y)</p><formula xml:id="formula_36">E θ (x, y) ∇ θ log E θ (x, y) (S46) ≈ E p(x,y) [∇ θ log E θ (x, y)] (S47) = ∇ θ E p(x,y) [log E θ (x, y)] = ∇ θ {I UBA (g θ )}. (S48)</formula><p>While the above relation shows we can use FLO to amortize the learning of UBA, one major caveat with the above formulation is that û(x, y) has to be very accurate for it to be valid. As such, one needs to solve a cumbersome nested optimization problem: update g θ , then optimize u φ until it converges before the next update of g θ . Fortunately, we can show that is unnecessary: the convergence can be established under much weaker conditions, which justifies the use of simple simultaneous stochastic gradient descent for both (θ, φ) in the optimization of FLO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof of Proposition 2.5 (FLO Convergence under SGD)</head><p>Our proof is based on the convergence analyses of generalized stochastic gradient descent from <ref type="bibr" target="#b73">[74]</ref>. We cite the main assumptions and results below for completeness.</p><p>Definition E.1 (Generalized SGD, Problem 2.1 in <ref type="bibr" target="#b73">[74]</ref>). Let h(θ; ω), ω ∼ p(ω) be an unbiased stochastic gradient estimator for objective f (θ), {η t &gt; 0} is the fixed learning rate schedule, {ξ t &gt; 0} is the random perturbations to the learning rate. We want to solve for ∇f (θ) = 0 with the iterative scheme θ t+1 = θ Proof. Since Êθt /E θt is bounded between [a, b] (0 &lt; a &lt; b &lt; ∞), results follow by a direct application of Proposition E.3 and Proposition E.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Gaussian Toy Model Experiments</head><p>First, we start validating the properties and utility of the proposed FLO estimator by comparing it to competing solutions with the Gaussian toy models. Specifically, for the 2d-D Gaussian model with correlation ρ, we have</p><formula xml:id="formula_37">X ∈ R d and Y ∈ R d with covariance structure cov[[X] i , [X] j ] = δ ij , cov[[Y ] i , [Y ] j ] = δ ij , cov[[X] i , [Y ] j ] = δ ij • ρ (S49)</formula><p>This allows us to have the ground-truth MI I(X; Y ) = − d 2 log(1 − ρ 2 ) for reference and easily tune the difficulty of the task via varying d and ρ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Choice of baselines</head><p>We choose TUBA, NWJ, InfoNCE and α-InfoNCE as our baselines. Note α-InfoNCE results are not reported in the main paper because we do not see a clear advantage via tuning α NWJ and InfoNCE are the two most popular estimators in practice that are employed without additional hacks. TUBA is included for its close relevance to FLO (i.e., optimizing u(x) instead of u(x, y), and being noncontrastive). We do not include DV here because we find DV needs excessively a large negative sample size K to work. Variants like MINE are excluded for involving additional tuning parameters or hacks p(x)p(y) using the 2D Gaussian experiment. This confirms our analyses that the optimized u(x, y) approximates the true PMI.</p><p>which complicates our analyses. The proposed FDV estimator is also excluded from our analyses for bound comparison since it includes ÎDV in the estimator. Note that although not suitable for MI estimation, we find FDV works quite well in representation learning settings where the optimization of MI is targeted. This is because in FDV, the primal term ÎDV term does not participate gradient computation, so it does not yield degenerated performance as that of DV. In the results reported below, we fixed α = 0.8 for better visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Experimental setups</head><p>We use the following baseline setup for all models unless otherwise specified. For the critic functions g(x, y), u(x, y) and u(x), we use multi-layer perceptron (MLP) network construction with hiddenlayers 512 × 512 and ReLU activation. For optimizer, we use Adam and set learning rate to 10 −4 unless otherwise sepcified. A default batch-size of 128 is used for training. To report the estimated MI, we use 10k samples and take the average. To visualize variance, we plot the decimal quantiles at {10%, 20%, • • • , 80%, 90%} and color code with different shades. We sample fresh data point in each iteration to avoid overfitting the data. All models are trained for ∼ 5, 000 iterations (each epoch samples 10k new data points, that is 78 iterations per epoch for a total of 50 epochs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 PMI approximation with u(x, y)</head><p>For Figure <ref type="figure" target="#fig_9">S11</ref>, we use the 2-D Gaussian with ρ = 0.5 to compare the estimated u(x, y), g(x, y) with the ground-truth PMI, and the contour plot is obtained with a grid resolution of 2.5 × 10 −2 . This confirms our analyses that the optimized u(x, y) approximates the true PMI − log p(x,y) p(x)p(y) .</p><p>F.4 Ablation study: efficiency of parameter sharing for g(x, y) and u(x, y).</p><p>For the shared parameterization experiment for FLO (Figure <ref type="figure" target="#fig_0">S12</ref>), we used the more challenging 20-D Gaussian with ρ = 0.5, and trained the network with learning rate 10 −3 and 10 −4 respectively. We repeat the experiments for 10 times and plot the distribution of the MI estimation trajectories. Note that we intentionally used a setup such that the MLP network architecture we used is inadequate to get a sharp estimate (both for FLO and other MI estimators), which simulates the realistic scenario that the ground-truth MI is infeasible due to architecture constraints (refer to our ablation study on the influence network capacity in Sec F.5). We observe the FLO estimator with a shared network learns faster than its separate network counterpart under both learning rates, validating the superior efficiency of parameter sharing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.5 Ablation study: network capacity and MI estimation accuracy</head><p>We further investigate how the neural network learning capacity affect MI estimation. In Figure <ref type="figure" target="#fig_2">S13</ref> we compare the training dynamics of the FLO estimator with L-layer neural networks, where L ∈ {2, 3, 6} and each hidden-layer has 512-units. A deeper network is generally considered to be more expressive. We see that using larger networks in general converge faster in terms of training Figure <ref type="figure" target="#fig_2">S13</ref>: Abaltion study for network complexity with FLO. More complex networks lead to faster convergence and better MI estimates. However, the stability is more sensitive to learning rate with a larger neural network.</p><p>iterations, and also obtain better MI estimates. However, more complex networks imply more computation per iteration, and it can be less stable when trained with larger learning rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.6 Ablation study: Bi-linear critics and scaling</head><p>We setup the bi-linear critic experiment as follows. For the naive baseline FLO, we use the sharednetwork architecture for g(x, y) and u(x, y), and use the in-batch shuffling to create the desired number of negative samples (FLO-shuff). For FLO-BiL, we adopt the following implementation: feature encoders h(x), h(y) are respectively modeled with three layer MLP with 512-unit hidden layers and ReLU activations, and we set the output dimension to 512. Then we concatenate the feature representation to z = [h(x), h(y)] and fed it to the u(x, y) network, which is a two-layer 128-unit MLP. Note that is merely a convenient modeling choice and can be further optimized for efficiency. Each epoch containing 10k samples, and FLO-shuff is trained with fixed batchsize. For FLO-BiL, it is trained with batch-size set to the negative sample-size desired, because all in-batch data are served as negatives. We use the same learning rate 10 −4 for both cases, and this puts large-batch training at disadvantage, as fewer iterations are executed. To compensate for this, we use T (K) = ( K K0 )</p><p>1 2 • T 0 to set the total number of iterations for FLO-BiL, where (T 0 , K 0 ) are respectively the baseline training iteration and negative sample size used by FLO-shuff, and the number of negative sample K are {10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500}. We are mostly interested in computation efficiency here so we do not compare the bound. In Figure <ref type="figure" target="#fig_0">S14</ref>, we see the cost for training FLO-shuff grows linearly as expected. For FLO-BiL, a U-shape cost curve is observed. This is because bilinear implementation has three networks total, while the shared MLP  only have one network. This implies more computations when the batch size is small, however, as the batch size grows, the computation overhead is amortized by better parallelism employed with the bilinear strategy, thus increasing overall efficiency until the device capacity has been reached. This explains the initial drop in cost, followed by the anticipated square-root growth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.7 Comparison of learning dynamics for different variational MI bounds</head><p>In Figure <ref type="figure" target="#fig_8">S15</ref>, we show the learning dynamics of competing estimators for the 20-D Gaussian when ρ = 0.9. We can find FLO achieves the best accuracy, it also learns fast and stably. InfoNCE learns very stably, yet its learning efficiency varies significantly in small-batch and large-batch setups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.8 Comprehensive analyses of bias-variance trade-offs</head><p>To supplement our results in the main paper, here we provide additional bias-variance plots for different MI estimators under various settings. In Figure <ref type="figure" target="#fig_11">S16</ref> we show the bias-variance plot of MI estimates for 2-D Gaussians. In this case, the network used are sufficiently comprehensive so sharp estimate is attainable. In all cases the estimation variance grows with MI value, which is consistent with the theoretical prediction that for tight estimators, the estimation variance grows exponential   with MI <ref type="bibr" target="#b54">[55]</ref>. In such cases, the argument for InfoNCE's low-variance profile no longer holds: it is actually performing sub-optimally. For complex real applications, the negative sample size used might not provide an adequate estimate of ground-truth MI (i.e., the log K cap), and that is when InfoNCE's low-variance profile actually helps. We also notice that, when the MI estimate is not exactly tight, but very close to the true value, the variance dropped considerably. This might provide alternative explanation (and opportunity) for the development near-optimal MI estimation theories, which is not covered in existing literature.</p><p>We also tried the single-sample estimators for NWJ, TUBA and FLO to their multi-sample InfoNCEbased counterparts (Figure <ref type="figure" target="#fig_12">S17</ref>), which is the comparison made by some of the prior studies (Note we do not apply Bilinear tric here, thus FLO seems similar to other methods). In this setting, the variance single-sample estimators' variances are considerably larger, which explains their less favorable performance. Note that contradictory to theoretical predictions, a larger negative sample size does make NWJ, TUBA and FLO tighter empirically, although the gains are much lesser compare to that of InfoNCE (partly because these three estimators are already fairly tight relative to InfoNCE). This might be explained by a better optimization landscape due to reduced estimation variance. We conjecture that for multi-sample NWJ, TUBA and FLO, the performance in empirical applications such as self-supervised learning should be competitive to that of InfoNCE, which has never been reported in literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Cross-view Representation Learning (Extended Analyses)</head><p>In addition to the results reported in the paper, we investigate how different latent dimension affect the results of the cross-view representation learning. We vary the latent dimension number from d = 2 to d = 20, and plot label prediction accuracy for the corresponding latent representations in Figure <ref type="figure" target="#fig_13">S18</ref>. The same setup for the bi-linear experiment is used for the MI estimation (for all MI estimators), where the images are flattened to be fed to the MLPs. The representations are trained for With multiple demographic groups, it is the maximal disparities between any two groups: DP( Ŷ , S) = max</p><formula xml:id="formula_38">s =s P( Ŷ = 1|S = s) − P( Ŷ |S = s ) . (S51)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2 Experiment details and analyses</head><p>To scrub the sensitive information from data, we consider the in-processing setup L = Loss(Predictor(Encoder(x i )), y i Primary loss</p><p>) + λ I(s i , Encoder(x i ))</p><p>Debiasing .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(S52)</head><p>By regularizing model training with the violation of specified fairness metric ∆(ŷ, s), fairness is enforced during model training. In practice, people recognize that appealing to fairness sometimes cost the utility of an algorithm (e.g., prediction accuracy) <ref type="bibr" target="#b36">[37]</ref>. So most applications seek to find their own sweet points on the fairness-utility curve. In our example, it is the DP-error curve. A fair-learning algorithm is consider good if it has lower error at the same level of DP control.</p><p>In this experiment, we compare our MI-based fair learning solutions to the state-of-the-art methods.</p><p>Adversarial debiasing tries to maximize the prediction accuracy for while minimize the prediction accuracy for sensitivity group ID <ref type="bibr" target="#b86">[87]</ref>. We use the implementation from AIF360 13 package <ref type="bibr" target="#b12">[13]</ref>. FERMI is a density-based estimator for the exponential Rényi mutual information ERMI E p(x,y) [ p(x,y) p(x)p(y) ], and we use the official codebase. For evaluation, we consider the adult data set from UCI data repository <ref type="bibr" target="#b6">[7]</ref>, which is the 1994 census data with 30k samples in the train set and 15k samples in the test set. The target task is to predict whether the income exceeds $50k, where gender is used as protected attribute. Note that we use this binary sensitive attribute data just to demonstrate our solution is competitive to existing solutions, where mostly developed for binary sensitive groups. Our solution can extend to more general settings where the sensitive attribute is continuous and high-dimensional.</p><p>We implement our fair regression model as follows. To embrace data uncertainty, we consider latent variable model p θ (y, x, z) = p θ (y|z)p θ (x|z)p(z), where v = {x, y} are the observed predictor and labels. Under the variational inference framework <ref type="bibr" target="#b44">[45]</ref>, we write the ELBO(v; p θ (v, z), q φ (z|v)) as</p><formula xml:id="formula_39">E Z∼q φ (z|v) [log p θ (y|Z)] + E Z∼q φ (z|v) [log p θ (x|Z)] − βKL(q φ (z|v) p(z)) (S53)</formula><p>p(z) is modeled with standard Gaussian, and the approximate posterior q φ (z|v) is modeled by a neural network parameterizing the mean and variance of the latents (we use the standard mean-field approximation so cross-covariance is set to zero), and β is a hyperparameter controlling the relative contribution of the KL term to the objective. Note that unlike in the standard ELBO we have dropped the term E Z∼q φ (z|v) [log p θ (x|Z)] because we are not interested in modeling the covariates. Note this coincides with the variational information bottleneck (VIB) formulation <ref type="bibr" target="#b1">[2]</ref>. Additionally, the posterior q φ (z|v) will not be conditioned on y, but only on x, because in practice, the labels y are not available at inference time. All networks used here are standard three-layer MLP with 512 hidden-units.</p><p>For Figure <ref type="figure">S20</ref>, we note that the adversarial de-biasing actually crashed in the DP range [0.1, 0.18], so the results have to be removed. Since interpolation is used to connect different data points, it makes the adversarial scheme look good in this DP range, which is not the case. FERMI also gave unstable estimation in the DP range [0.1, 0.18]. Among the MI-based solutions, NWJ was most unstable. Performance-wise, InfoNCE, TUBA and FDV are mostly tied, with the latter two slightly better in the "more fair" solutions (i.e., at the low DP end).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K Self-supervised Learning</head><p>Our codebase is modified from a public PyTorch implementation 14 . Specifically, we train 256dimensional feature representations by maximizing the self-MI between two random views of data, and report the test set classification accuracy using a linear classifier trained to convergence. We report performance based on ResNet-50, and some of the learning dynamics analyses are based </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L Bayesian Experimental Design L.1 Noisy Linear Model</head><p>Our setup is the same as the Noisy Linear Model in <ref type="bibr" target="#b46">[47]</ref>. We use 10 individual experimental designs.</p><p>For encoder θ and encoder y, we use MLP with 2-layer, 128-dim hidden layer, and set the feature dim as 512. We train models in 5000 epochs, the batch size is 64, and the learning rate is 2 * 10 −5 . Four MI estimators (NWJ, TUBA, InfoNCE, and FLO) has been compared in this experiment and we got four optimized designs. Then, we use MCMC to estimate the posterior of the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.2 Pharmacokinetic Model</head><p>The settings of this experiment refer to the Pharmacokinetic Model of <ref type="bibr" target="#b46">[47]</ref>. We use 10 individual experimental designs. The MLP is with 2-layer, 128-dim hidden layer, and set the output feature dim as 512. We train 10000 epochs with learning rate is 10 −5 via four methods (NWJ, TUBA, InfoNCE, FLO).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.3 SIR Model</head><p>We here consider the spread of a disease within a population of N individuals, mod-elled by stochastic versions of the well-known SIR <ref type="bibr" target="#b3">[4]</ref>. a susceptible state S(t) and can then move to an infectious state I(t) with an infection rate of β. These infectious individuals then move to a recovered state R(t) with a recovery rate of γ, after which they can no longer be infected. The SIR model, governed by the state changes S(t) → I(t) → R(t), thus has two model parameters θ 1 = (β, γ).</p><p>The stochastic versions of these epidemiological processes are usually defined by a continuous-time Markov chain (CTMC), from which we can sample via the Gillespie algorithm <ref type="bibr" target="#b2">[3]</ref>. However, this generally yields discrete population states that have undefined gradients. In order to test our gradientbased algorithm, we thus resort to an alternative simulation algorithm that uses stochastic differential equations (SDEs), where gradients can be approximated.</p><p>We first define population vectors X 1 (t) = (S(t), I(t)) for the SIR model and X 2 (t) = (S(t), E(t), I(t)) for the SEIR model. We can effectively ignore the population of recovered because the total population is fixed. The system of Itô SDEs for the above epidemiological processes is dX(t) = f (X(t)) dt + G(X(t)) dW (t), (S54) where f is the drift term, G is the diffusion term and W is the Wiener process. Euler-Maruyama algorithm is used to simulate the sample paths of the above SDEs. We use the infection rate (I) as 0.1 and the recovery (R) rate as 0.01. The independent priors are N(0.1,0.02) and N(0.01, 0.002). The initial infection number is 10. We update MI one time after updating sampler three steps.We use RNN network with 2 layer 64 dim hidden layer construction to decoder the sequential design. For meta-learning, we sample n-tasks for training and n -tasks for testing, respectively denoted as S 1:n and Stest 1:n . We further decouple the learning algorithm into two parts: the meta-learner A meta (S 1:n ) that consumes all train data to get the meta-model f meta , and then task-adaptation learner A adapt (f meta , S t ) which adapts the meta-model to the individual task data S t to get task model f t .</p><p>For parameterized models such as deep nets, we denote Θ as our meta parameters and E t as taskparameters, that is to say Θ A meta (S 1:n ), E t A adapt (Θ, S t ), where Θ, E t can be understood as weights of deep nets. In subsequent discussions, we will also call E t the task-embedding. We can define the population meta-risk as R τ (Θ) E t,Θ=Ameta(S1:n) [E Et=Aadapt(Θ,St) [R t (f Et )]], and similarly for the empirical risk Rτ evaluated on the query set Q t . Our model is based on the following inequality <ref type="bibr" target="#b4">[5]</ref>:</p><formula xml:id="formula_40">lim n→∞ |E[R − R]| ≤ 2σ 2 m I(E t ; S t |Θ) (S57)</formula><p>which gives the main objective L Meta-FLO (f ) = R(f ) + λ I FLO ( Dt ; Êt ). We summarize our model architecture in Figure <ref type="figure" target="#fig_16">S21</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic of variational lower bounds of mutual information. FLO provides a novel unified framework to analyze contrastive MI bounds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Bias-variance plot for popular variational MI bounds with the 10-D Gaussians. Estimators that are more concentrated around the dashed line is considered better (low-bias, low-variance). In the more challenging high-MI regime, FLO shows a clear advantage over competing alternatives, where FLO pays less price in variance to achieve even better accuracy when tight estimation is impossible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Diagnosis of learned sequential designs. The disease surveillance windows designed by FLO makes more sense: measures more frequently as infection spikes, and more sparsely when the pandemic slowly fades. The estimated parameter posterior (right) is consistent with the ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Few-shot adaptation with Meta-FLO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Sample efficiency comparison for SimCLR and FlatCLR on Cifar10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 9: Representation MI strongly correlates with performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>[N/A] 5 .</head><label>5</label><figDesc>If you used crowdsourcing or conducted research with human subjects... (a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A] (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure S11 :</head><label>S11</label><figDesc>FigureS11: Comparison of estimated u(x, y), g(x, y) and the ground-truth PMI − log p(x,y) p(x)p(y) using the 2D Gaussian experiment. This confirms our analyses that the optimized u(x, y) approximates the true PMI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>4 Figure S12 :</head><label>4S12</label><figDesc>Figure S12: MI estimation with different critic parameter sharing strategies for FLO: shared network and separate networks under learning rates 10 −3 and 10 −4 for 2-D Gaussian. Note shared parameterization not only reduced half the network size, it also learns faster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure S16 :</head><label>S16</label><figDesc>FigureS16: Bias variance plot for the popular MI bounds with the 2-D Gaussians. In this simpler case, TUBA, NWJ and FLO all give sharp estimate at K = 5. α-InfoNCE gives worst variance profile. The reason is that because α-InfoNCE interpolates between the low-variance multi-sample InfoNCE and high-variance single-sample NWJ (see FigureS17), and in this case the variance from NWJ dominates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure S17 :</head><label>S17</label><figDesc>Figure S17: Bias variance plot for the popular MI bounds with the 2-D (upper panel) and 20-D (lower panel) Gaussians. Single-sample estimator of TUBA, NWJ and FLO (i.e., K = 1) are compared to the multi-sample estimators of InfoNCE and α-InfoNCE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure S18 :</head><label>S18</label><figDesc>Figure S18: Extended results for the cross-view representation learning. FDV works best for smaller dimensions (≈ 5), and for higher dimensions (&gt; 10) FLO and InfoNCE give the best results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure S19 :</head><label>S19</label><figDesc>Figure S19: Comparison to classical MI estimators. (left) Easy2D Gaussian, all models perform similarly. (right) Challenging 20D Gaussian, where FLO shows better overall accuracy. Note that the kde accuracy in the high-dimensional setting is mis-judged, as it is well-known kernel-based density estimator scale poorly in high-dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure S21 :</head><label>S21</label><figDesc>Figure S21: Model architecture of Meta-FLO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>The sin-wave adaptation experiment involves regressing from the input (x ∼ Uniform([−5, 5])) to the output of a sine wave κ sin(x − γ), where amplitude κ ∼ Uniform([0.1, 5]) and phase (γ ∼ Uniform([0, π]) of the sinusoid vary for each task. We use mean-squared error (MSE) as our loss and set the support-size = 3 and query-size = 2. We use simple three-layer MLPs for all the models: regressor, prompt encoder, and FLO critics, with hidden units all set to [512, 512].During training, we use an episode-size of 64. For MAML, we use the first-order implementation (FOMAML), and set inner learning rate to α = 10 −4 . For Meta-FLO, we set regularization strength to λ = 10 −2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Multi-view representation learning on Cifar</figDesc><table><row><cell>Model</cell><cell>InfoNCE</cell><cell>SpecNCE [36] a</cell><cell>FLO</cell><cell>FDV</cell></row><row><cell>MI</cell><cell>5.73 ± .07</cell><cell>4.76 ± .08</cell><cell cols="2">5.83 ± .08 5.93 ± .08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>t + ηt h(θ t ; ω t ), where {ω t } are iid draws and ηt = η t ξ t is the randomized learning rate. The sequence {θ t } is bounded with probability 1;A4. The noise sequence {ω t } is a martingale difference sequence; A5. For some finite constants A and B and some norm• on R d , E[ ω t 2 ] ≤ A + B θ t 2 a.s. ∀t ≥ 1.Proposition E.3 (Generalized stochastic approximation, Proposition 2.2 in<ref type="bibr" target="#b73">[74]</ref>). Under the standard regularity conditions listed in Assumption E.2, we further assume t E[η t ] = ∞ and t E[η 2 t ] &lt; ∞. Then θ n → θ * with probability 1 from any initial point θ 0 . Assumption E.4. (Weaker regularity conditions for generalized Robbins-Monro stochastic approximation, Assumption G.1 in<ref type="bibr" target="#b73">[74]</ref>).</figDesc><table><row><cell>Assumption E.2. (Standard regularity conditions for Robbins-Monro stochastic approximation,</cell></row><row><cell>Assumption D.1 [74]).</cell></row><row><cell>A1. h(θ) E ω [h(θ; ω)] is Lipschitz continuous;</cell></row><row><cell>A2. The ODE θ = h(θ) has a unique equilibrium point θ  *  , which is globally asymptotically</cell></row><row><cell>stable;</cell></row><row><cell>A3.</cell></row></table><note>B1. The objective function f (θ) is second-order differentiable. B2. The objective function f (θ) has a Lipschitz-continuous gradient, i.e., there exists a constant L satisfying −LI ∇ 2 f (θ) LI, B3. The noise has a bounded variance, i.e., there exists a constant σ &gt; 0 satisfying E h(θ t ; ω t ) − ∇f (θ t ) 2 ≤ σ 2 . Proposition E.5 (Weaker convergence results, Proposition G.2 in [74]). Under the technical conditions listed in Assumption E.4, the SGD solution {θ t } t&gt;0 updated with generalized Robbins-Monro sequence (η t : t E[η t ] = ∞ and t E[η 2 t ] &lt; ∞) converges to a stationary point of f (θ) with probability 1 (equivalently, E ∇f (θ t ) 2 → 0 as t → ∞).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Gaussian at ρ = 0.9. We used bilinear critics for all bounds. Note InfoNCE enjoys stable learning, and its convergence is fast in the small-sample regime but slow in the largesample regime. In all cases InfoNCE suffers form large biases. NWJ is more accurate but it learns slower. In contrast, our FLO learns fast and stably.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="4">Batch Size scaling</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>6k</cell><cell></cell><cell cols="3">(g,u) shared Bilinear</cell><cell></cell><cell></cell><cell></cell><cell>6 7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time (Sec)</cell><cell>0.5k 1.2k 3k</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128</cell><cell>256</cell><cell>512</cell><cell>MI</cell><cell>3 4 5 0 1 2</cell><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>200 Epochs FLO-512 250 TUBA-512 NWJ-512 InfoNCE-512</cell><cell>300</cell><cell>350 InfoNCE-1024 400 InfoNCE-2048 True MI</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">Negative Sample Size K</cell><cell></cell><cell cols="9">Figure S15: Comparison of learning dynamics</cell></row><row><cell cols="8">Figure S14: Comparison of computation time</cell><cell cols="3">with 20-D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">of the shared MLP critic and the bi-linear critic.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">Overall the bilinear implementation is more ef-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">ficient than the shared MLP. FLO's initial drop</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">in computation time with growing negative sam-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">ple size is due to better exploitation of parallel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">computation.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table S2 :</head><label>S2</label><figDesc>MNIST cross-view results. Model CCA NWJ TUBA InfoNCE FLO FDV Accuracy 67.78 76.71 79.49 79.27 79.47 80.14 Î(x l , x r ) NA 5.73 4.78 4.65 4.84 4.67 on ResNet-18 reasons of memory constraints. Hyper-parameters are adapted from the original SimCLR paper. For the large-batch scaling experiment, we first grid-search the best learning rate for the base batch-size, then grow the learning rate linearly with batch-size.</figDesc><table><row><cell></cell><cell>0.28</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>InfoNCE</cell><cell>FLO</cell></row><row><cell></cell><cell>0.26</cell><cell></cell><cell></cell><cell></cell><cell>FDV TUBA</cell><cell>Adversarial FERMI</cell></row><row><cell>Error</cell><cell>0.22 0.24</cell><cell></cell><cell></cell><cell></cell><cell>NWJ</cell></row><row><cell></cell><cell>0.20</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.18</cell><cell>0.00</cell><cell>0.05</cell><cell>0.10</cell><cell>0.15</cell><cell>0.20</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Demographic Parity</cell></row><row><cell cols="7">Figure S20: Fair Learning Result.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">When estimates are sharp, these critic functions usually recover some transformation of the likelihood ratio.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In the sense that they do not render closed-from expressions.<ref type="bibr" target="#b2">3</ref> Formally,I(X; Y ) = H(X) − H(X|Y ) = H(Y ) − H(Y |X), where H(X) (resp. H(X|Y )) denotes the Shannon entropy (resp. conditional Shannon entropy) of a random variable.<ref type="bibr" target="#b3">4</ref> This estimator is technically equivalent to the original definition due to the symmetry of K samples.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">As an important note to the community, most open source implementations for the bilinear contrastive loss have mechanically implemented<ref type="bibr" target="#b0">1</ref> T •, • following the practice from pioneering contrastive learning studies, which is numerically unstable compared to our parameterization τ •, • proposed here.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">That is to say g θ in u φ is an independent copy of g θ .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Ground-truth MI is approximated by InfoNCE using a very large negative sample pool (100× mini-batch).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">https://github.com/Trusted-AI/AIF360 14 https://github.com/sthalles/SimCLR</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the anonymous reviewers for their insightful comments. Q Guo gratefully appreciate the support of Amazon Fellowship. X Deng would like to thank the Advanced Research Computing program at Virginia Tech and Virginia's Commonwealth Cyber Initiative (CCI) AI testbed for providing computational resources, also appreciate the CCI and CCI-Coastal grants to Virginia Tech. Part of this work is done before C Tao joined Amazon, and he was funded by National Science Foundation Grant No. 1934964. This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562 <ref type="bibr" target="#b77">[78]</ref> and used the Extreme Science and Engineering Discovery Environment (XSEDE) PSC Bridges-2 and SDSC Expanse at the service-provider through allocation TG-ELE200002 and TG-CIS210044.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We can bound MI from below using an variational distribution q(y|x) as follows:</p><p>In sample-based estimation of MI, we do not know the ground-truth marginal density p(y), which makes the above BA bound impractical. However, we can carefully choose an energy-based variational density that "cancels out" p(y):</p><p>This auxiliary function f (x, y) is known as the tilting function in importance weighting literature.</p><p>Hereafter, we will refer to it the critic function in accordance with the nomenclature used in contrastive learning literature. The partition function Z f (x) normalizes this q(y|x). Plugging this q f (y|x) into I BA yields:</p><p>For x, a &gt; 0, we have inequality log(x) ≤ x a + log(a) − 1. By setting x ← Z(y) and a ← e, we have log(Z(y)) ≤ e −1 Z(y).</p><p>(S22) Plugging this result into (S21) we recover the celebrated NWJ bound, which lower bounds I UBA :</p><p>When f (x, y) takes the value of</p><p>this bound is sharp.</p><p>We next extend these bounds to the multi-sample setting. In this setup, we are given one paired sample (x 1 , y 1 ) from p(x, y) (i.e., the positive sample) and K − 1 samples independently drawn from p(y) (i.e., the negative samples). Note that when we average over x wrt p(x) to compute the MI, this equivalent to comparing positive pairs from p(x, y) and negative pairs artificially constructed by p(x)p(y). By the independence between X 1 and Y k&gt;1 , we have</p><p>50 epochs and the prediction model is trained for 50 epochs. We also trained the model for another 50 epochs and the conclusions are similar. We see that FDV works well for lower dimensions (e.g., d ≈ 5), and what works better for higher dimensions (d &gt; 10) are FLO and InfoNCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Comparison with Classical MI Estimators</head><p>We also compare our FLO estimator to the classical MI estimators in Figure <ref type="figure">S19</ref>. The following implementations of baseline estimators for multi-dimensional data are considered: (i) KDE: we use kernel density estimators to approximate the joint and marginal likelihoods, then compute MI by definition; (ii) NPEET 8 , a variant of Kraskov's K-nearest neighbour (KNN) estimator <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b79">80]</ref>;</p><p>(iii) KNNIE 9 , the original KNN-estimator and its revised variant <ref type="bibr" target="#b27">[28]</ref>. These models are tested on 2-D and 20-D Gaussians with varying strength of correlation, with their hyper-parameters tuned for best performance. Note that the notation of "best fit" is a little bit subjective, as we will fix the hyper-parameter for all dependency strength, and what works better for weak dependency might necessarily not work well for strong dependency. We choose the parameter whose result is visually most compelling. In addition to the above, we have also considered other estimators such as maximallikelihood density ratio 10 [73] and KNN with local non-uniformity correction 11 . However, these models either do not have a publicly available multi-dimensional implementation, or their codes do not produce reasonable results 12 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Comparison to Parametric Variational Estimators and Bounds Targeting Alternative Information Metrics</head><p>Parametric variational estimators are typically associated with upper bound of MI <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b64">65]</ref>. Inspired by multi-sample variational bounds for likelihood estimation, <ref type="bibr" target="#b15">[16]</ref> derived a generic family of importanceweighted MI bounds that are provably tighter. These bounds usually require the additional knowledge of likelihood, and consequently they can not be directly used for data-driven MI estimations. On the other hand, these models do not suffer from the exponential scaling of variance suffered by non-parametric MI estimators. Note that MI is not the only measure to assess association between two random variables, some alternatives can potentially do better for specific applications. Examples include V information <ref type="bibr" target="#b84">[85]</ref>, Rényi information <ref type="bibr" target="#b49">[50]</ref>, and the spectral information <ref type="bibr" target="#b35">[36]</ref>.</p><p>J Regression with Sensitive Attributes (Fair Learning) Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.1 Introduction to fair machine learning</head><p>Nowadays consequential decisions impacting people's lives have been increasingly made by machine learning models. Such examples include loan approval, school admission, and advertising campaign, amongst others. While automated decision making has greatly simplified our lives, concerns have been raised on (inadvertently) echoing, even amplifying societal biases. Specially, algorithms are vulnerable in inheriting discrimination from the training data and passed on such prejudices in their predictions.</p><p>To address the growing need for mitigating algorithmic biases, research has been devoted in this direction under the name fair machine learning. While discrimination can take many definitions that are not necessarily compatible, in this study we focus on the most widely recognized criteria Demographic Parity (DP), as defined below Definition J.1 (Demographic Parity, <ref type="bibr" target="#b21">[22]</ref>). The absolute difference between the selection rates of a decision rule ŷ of two demographic groups defined by sensitive attribute s, i.e., DP( Ŷ , S) = P( Ŷ = 1|S = 1) − P( Ŷ = 1|S = 0) . (S50) 8 https://github.com/gregversteeg/NPEET 9 https://github.com/wgao9/knnie 10 https://github.com/leomuckley/maximum-likelihood-mutual-information 11 https://github.com/BiuBiuBiLL/NPEET_LNC 12 These are third-party python implementations, so BUGs are highly likely.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fixing a broken ELBO</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep variational information bottleneck</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Alexander A Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A primer on stochastic epidemic models: Formulation, numerical simulation, and analysis</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Linda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infectious Disease Modelling</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="142" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Linda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauline</forename><surname>Brauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhong</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical epidemiology</title>
		<imprint>
			<biblScope unit="volume">1945</biblScope>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Principled simple fast few-shot learning with stochastic prompt encoding networks</title>
		<author>
			<persName><surname>Anonymous</surname></persName>
		</author>
		<author>
			<persName><surname>Meta-Flo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Uci machine learning repository</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Asuncion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kernel independent component analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael I Jordan</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2002-07">Jul. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The IM algorithm: a variational approach to information maximization</title>
		<author>
			<persName><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Agakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">201</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Information maximization in noisy channels: A variational approach</title>
		<author>
			<persName><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><surname>Felix V Agakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using mutual information for selecting features in supervised neural net learning</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="537" to="550" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">Ishmael</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aristide</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sai</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">AI Fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Rachel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuntal</forename><surname>Bellamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><surname>Hind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalapriya</forename><surname>Houde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranay</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacquelyn</forename><surname>Lohia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameep</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seema</forename><surname>Mojsilovic</surname></persName>
		</author>
		<author>
			<persName><surname>Nagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Karthikeyan Natesan Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diptikalyan</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moninder</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kush</forename><forename type="middle">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfeng</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-10">October 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Statistical decision theory and Bayesian analysis</title>
		<author>
			<persName><forename type="first">O</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving mutual information estimation with annealed and energy-based bounds</title>
		<author>
			<persName><forename type="first">Rob</forename><surname>Brekelmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzyeh</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">Ver</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Baker Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bayesian experimental design: A review</title>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Chaloner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabella</forename><surname>Verdinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="page" from="273" to="304" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Junya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tagyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlian</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.01152</idno>
		<title level="m">faster, stronger: Breaking the log-K curse on contrastive learners with flatnce</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CLUB: A contrastive log-ratio upper bound of mutual information</title>
		<author>
			<persName><forename type="first">Pengyu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weituo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Asymptotic evaluation of certain markov process expectations for large time</title>
		<author>
			<persName><forename type="first">D</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><surname>Donsker</surname></persName>
		</author>
		<author>
			<persName><surname>Sr Srinivasa Varadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">iv. Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="212" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd innovations in theoretical computer science conference</title>
				<meeting>the 3rd innovations in theoretical computer science conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep adaptive design: Amortizing sequential bayesian experimental design</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilyas</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Rainforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Variational bayesian optimal experimental design</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jankowiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Horsfall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified stochastic gradient approach to designing bayesian-optimal experiments</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jankowiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Meara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><surname>Rainforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient estimation of mutual information for strongly dependent variables</title>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">Ver</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Demystifying fixed k-nearest neighbor information estimators</title>
		<author>
			<persName><forename type="first">Weihao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewoong</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pramod</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5629" to="5661" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the convergence of monte carlo maximum likelihood calculations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="261" to="274" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Kernel methods for measuring independence</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The kernel mutual information</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
				<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><forename type="middle">Daniel</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Umang</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Ferber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bistra</forename><surname>Dilkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">Ver</forename><surname>Steeg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04108</idno>
		<title level="m">Controllable guarantees for fair outcomes via contrastive information estimation</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Provable guarantees for selfsupervised deep learning with spectral contrastive loss</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Jeff Z Haochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Predictive entropy search for efficient global optimization of black-box functions</title>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Fundamentals of convex analysis</title>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claude</forename><surname>Lemaréchal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models by score matching</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="695" to="709" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Implicit deep adaptive design: Policy-based experimental design without likelihoods</title>
		<author>
			<persName><forename type="first">Desislava</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Michael U Gutmann</surname></persName>
		</author>
		<author>
			<persName><surname>Rainforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sequential bayesian experimental design for implicit models via mutual information</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Drovandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">U</forename><surname>Gutmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bayesian experimental design for implicit models by mutual information neural estimation</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><surname>Michael U Gutmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Gradient-based bayesian experimental design for implicit models using mutual information lower bounds</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><surname>Michael U Gutmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04379</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Estimating mutual information</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kraskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Stögbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Grassberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">66138</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">RényiCL: Contrastive representation learning with skew rényi divergence</title>
		<author>
			<persName><forename type="first">Kyungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Self-organization in a perceptual network</title>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Noise contrastive estimation and negative sampling for conditional models: Consistency and statistical efficiency</title>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01812</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Information theory, inference and learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Mackay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multimodality image registration by maximization of mutual information</title>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Collignon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Marchal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="198" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Formal limitations on the measurement of mutual information</title>
		<author>
			<persName><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.04251</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning word embeddings efficiently with noisecontrastive estimation</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Annealed importance sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="139" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Estimating divergence functionals and the likelihood ratio by convex risk minimization</title>
		<author>
			<persName><forename type="first">Xuanlong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael I Jordan</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5847" to="5861" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka. F-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Predictive information in a sensory population</title>
		<author>
			<persName><forename type="first">E</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><surname>Marre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="6908" to="6913" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Estimation of entropy and mutual information</title>
		<author>
			<persName><forename type="first">Liam</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1191" to="1253" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Estimation of information theoretic measures for continuous random variables</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Pérez-Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Mutual-information-based registration of medical images: a survey</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Josien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><forename type="middle">A</forename><surname>Maintz</surname></persName>
		</author>
		<author>
			<persName><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="986" to="1004" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00020</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">On nesting monte carlo estimators</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Cornish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongseok</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">A modern course in statistical physics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Linda</surname></persName>
		</author>
		<author>
			<persName><surname>Reichl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Detecting novel associations in large data sets</title>
		<author>
			<persName><surname>David N Reshef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yakir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hilary</forename><forename type="middle">K</forename><surname>Reshef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharon</forename><forename type="middle">R</forename><surname>Finucane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilean</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><surname>Mcvean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">S</forename><surname>Turnbaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pardis C</forename><surname>Mitzenmacher</surname></persName>
		</author>
		<author>
			<persName><surname>Sabeti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="issue">6062</biblScope>
			<biblScope unit="page" from="1518" to="1524" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">A mathematical theory of communication. The Bell system technical journal</title>
		<author>
			<persName><forename type="first">Claude</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948">1948</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Opening the black box of deep neural networks via information</title>
		<author>
			<persName><forename type="first">Ravid</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Ziv</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00810</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Understanding the limitations of variational mutual information estimators</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Approximating mutual information by maximum likelihood density ratio estimation. In New challenges for feature selection in data mining and knowledge discovery</title>
		<author>
			<persName><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takafumi</forename><surname>Kanamori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">On Fenchel mini-max learning</title>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgiy</forename><surname>Bobashev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Deep learning and the information bottleneck principle</title>
		<author>
			<persName><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noga</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Information Theory Workshop (ITW)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Feature extraction by non-parametric mutual information maximization</title>
		<author>
			<persName><forename type="first">Kari</forename><surname>Torkkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Xsede: accelerating scientific discovery</title>
		<author>
			<persName><forename type="first">John</forename><surname>Towns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Cockerill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maytal</forename><surname>Dahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelly</forename><surname>Gaither</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Grimshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hazlewood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Lifka</surname></persName>
		</author>
		<author>
			<persName><surname>Gregory D Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in science &amp; engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="62" to="74" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">On mutual information maximization for representation learning</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Paul K Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><surname>Lucic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Information-theoretic measures of influence based on content dynamics</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Ver Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM international conference on Web search and data mining</title>
				<meeting>the sixth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Mutual information gradient estimation for representation learning</title>
		<author>
			<persName><forename type="first">Liangjian</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiji</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lirong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zenglin</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Experiments: planning, analysis, and optimization</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Cf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Hamada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">552</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Information-theoretic analysis of generalization capability of learning algorithms</title>
		<author>
			<persName><forename type="first">Aolin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Raginsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A theory of usable information under computational constraints</title>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Provable stochastic optimization for global contrastive learning: Small batch does not harm performance</title>
		<author>
			<persName><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi-Hao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Mitigating unwanted biases with adversarial learning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hu Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Lemoine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</title>
				<meeting>the 2018 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="335" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A robust approach to sequential information theoretic planning</title>
		<author>
			<persName><forename type="first">Sue</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
